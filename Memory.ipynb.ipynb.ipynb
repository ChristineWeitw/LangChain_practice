{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c876c7",
   "metadata": {},
   "source": [
    "# To enable LLM's memory (remembering the context)\n",
    "remember previous parts of the conversation and feed that into the language model so that they can have this \n",
    "conversational flow as you're interacting with them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1114ae",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory : store all messages.\n",
    "* ConversationBufferWindowMemory : store conversations based on the number of window in parameter setting. eg. when k=1, store only the latest conversation input.\n",
    "* ConversationTokenBufferMemory : store conversations based on the number of tokens in parameter setting. eg. when max_token_limit=100, store only the latest 100 words from conversation input.\n",
    "* ConversationSummaryMemory : store the summary of the input text with limited token number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b82151",
   "metadata": {},
   "source": [
    "# OpenAI API key access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55991341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426f3f7",
   "metadata": {},
   "source": [
    "# ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98be2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342401b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and set the memory type to \"ConversationBufferMemory\"\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b477eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Christine.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Christine! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert a few input msg\n",
    "conversation.predict(input=\"Hi, my name is Christine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3390dcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Christine.\n",
      "AI: Hello Christine! It's nice to meet you. How can I assist you today?\n",
      "Human: What is the weather like today in Toronto?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to real-time data. However, you can easily check the weather in Toronto by using a weather website or app.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert a few input msg\n",
    "conversation.predict(input=\"What is the weather like today in Toronto?\")\n",
    "\n",
    "''' you can see from Current conversation, the conversations are being stored in the memory.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c027ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Christine.\n",
      "AI: Hello Christine! It's nice to meet you. How can I assist you today?\n",
      "Human: What is the weather like today in Toronto?\n",
      "AI: I'm sorry, but I don't have access to real-time data. However, you can easily check the weather in Toronto by using a weather website or app.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Christine.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if the model memorize the information from the last conversation\n",
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193d119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store input, output manually, use 'save_context'\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd6179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Christine.\n",
      "AI: Hello Christine! It's nice to meet you. How can I assist you today?\n",
      "Human: What is the weather like today in Toronto?\n",
      "AI: I'm sorry, but I don't have access to real-time data. However, you can easily check the weather in Toronto by using a weather website or app.\n",
      "Human: What is my name?\n",
      "AI: Your name is Christine.\n",
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "# To check what content has memory saved\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b75dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Christine.\\nAI: Hello Christine! It's nice to meet you. How can I assist you today?\\nHuman: What is the weather like today in Toronto?\\nAI: I'm sorry, but I don't have access to real-time data. However, you can easily check the weather in Toronto by using a weather website or app.\\nHuman: What is my name?\\nAI: Your name is Christine.\\nHuman: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check what content has memory saved. Can add more specific parameter in the bracket to tune the output.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe53ea2",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26b7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7391f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by setting k=1, the memory saves only the last 1 window conversation\n",
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4990b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 window\n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "# 2 window\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ced380f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what content has memory saved\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "''' it saves only the last 1 window of conversation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4289a0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Tom! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To test with LLM, with ConversationBufferWindowMemory k=1\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi, my name is Tom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121a9fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Starbucks is a well-known coffeehouse chain that was founded in 1971 in Seattle, Washington. It has since become one of the largest and most recognizable coffeehouse chains in the world, with thousands of locations in various countries. Starbucks is known for its wide range of coffee and tea beverages, as well as its pastries, sandwiches, and other food items. The company also sells whole bean coffee, coffee accessories, and other merchandise. Starbucks is often a popular destination for people looking for a place to relax, work, or socialize.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random msg \n",
    "conversation.predict(input=\"What is starbucks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f070a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  To test if the model save the memory of what's the user's name, prior to the lastest window of conversation\n",
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ef197",
   "metadata": {},
   "source": [
    "# ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d672a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp38-cp38-macosx_10_9_x86_64.whl (798 kB)\n",
      "\u001b[K     |████████████████████████████████| 798 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.26.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2023.6.3-cp38-cp38-macosx_10_9_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (1.26.4)\n",
      "Installing collected packages: requests, regex, tiktoken\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\u001b[0m\n",
      "Successfully installed regex-2023.6.3 requests-2.31.0 tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af6308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a87e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the memory type to ConversationTokenBufferMemory, and limit the token number to only 30 words\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0f66a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf4f28",
   "metadata": {},
   "source": [
    "# ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a4dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52186204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
