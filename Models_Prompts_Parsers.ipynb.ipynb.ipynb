{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b96c4e3",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts : the style of creating inputs to pass into the models. \n",
    "   * Models : language models\n",
    "   * Output parsers : It involves taking the output of these models and parsing it into a more structured forma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dba4f9",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7dd4a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from openai) (2.25.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-macosx_10_9_x86_64.whl (359 kB)\n",
      "\u001b[K     |████████████████████████████████| 359 kB 3.0 MB/s eta 0:00:01     |██████████                      | 112 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from openai) (4.59.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (4.0.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christinewei/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (20.3.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.2.0-cp38-cp38-macosx_10_9_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-macosx_10_9_x86_64.whl (36 kB)\n",
      "Installing collected packages: multidict, frozenlist, yarl, charset-normalizer, async-timeout, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.2.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "# Set up environment\n",
    "# !pip install python-dotenv\n",
    "# !pip install openai\n",
    "# !pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9472319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46fd797",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a9f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e01a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "我打冰沙的時候，蓋子不小心飛出去 \\\n",
    "冰沙全部噴出來，濺到牆上 \\\n",
    "更慘的是\\\n",
    "機器保證書上並不包含清潔廚房\\\n",
    "老友 \\\n",
    "偶需要你幫忙\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a79dea",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain.\n",
    "\n",
    "Why not just use f\"string\" but using \"prompt_template\" in LangChain?\n",
    "##### As you build sophisticated applications,  prompts can be quite long and detailed. And so, \"prompt templates\" are a useful abstraction to help you reuse good prompts when you can. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d33e63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "    # To control the randomness and creativity of the generated\n",
    "    # text by an LLM, use temperature = 0.0\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "template_string = prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=style,\n",
    "                    text=customer_email)\n",
    "\n",
    "# Call the model\n",
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c31e09",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936d1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a9ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbecf564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ad2c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite and respecful tone that speaks in English . text: ```哈囉妳好 客戶兒, 我們的保固不包含清理服務 這不是基本常識ㄇ？ 是你自己亂用果汁機 還忘記蓋蓋子 請記取教訓 掰掰啦 再會\n",
      "```\n",
      "\n",
      "Hello, dear customer. Our warranty does not cover cleaning services. Isn't this common knowledge? It seems that you have used the juicer improperly by forgetting to put on the lid. Please take this as a lesson learned. Goodbye and take care. See you again.\n"
     ]
    }
   ],
   "source": [
    "# Using another example with LangChain\n",
    "\n",
    "service_reply = \"\"\"哈囉妳好 客戶兒, \\\n",
    "我們的保固不包含清理服務 \\\n",
    "這不是基本常識ㄇ？ \\\n",
    "是你自己亂用果汁機 還忘記蓋蓋子 \\\n",
    "請記取教訓 \\\n",
    "掰掰啦 \\\n",
    "再會\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite and respecful tone \\\n",
    "that speaks in English \\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)\n",
    "\n",
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba856912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4324c",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "The output from LLM model is a string, and we want to change it to JSON type later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4e0d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c022ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94f94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n",
      "message [HumanMessage(content=\"For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\\n\\n\", additional_kwargs={}, example=False)]\n",
      "{\n",
      "  \"gift\": false,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "print('message', messages)\n",
    "\n",
    "# create Langchain Model\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c4934c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8f1af029a88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gift'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a33f40",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "938cc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d513bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3 types of schemas and parse them into a list\n",
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f9916d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# having the output parser tell you what instructions it wants you to send to the LLM.\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61199151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# create 'format instructions' variable, it includes precise set of instructions for the LLM that will cause it to generate an output that the output parser can process.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4e1941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n",
      "type:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)\n",
    "print(messages[0].content)\n",
    "\n",
    "# call LLM model\n",
    "response = chat(messages)\n",
    "print(response.content)\n",
    "print(\"type: \", type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "181c0456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gift': False,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call output_parser to convert string into json\n",
    "output_dict = output_parser.parse(response.content)\n",
    "print(type(output_dict))\n",
    "output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51e4ae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf34ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
